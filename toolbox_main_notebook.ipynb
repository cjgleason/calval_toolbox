{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7901617d-d7e3-4675-b474-1be621886f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/nas/cee-water/cjgleason/calval/Processed data/UMass/'"
      ],
      "text/latex": [
       "'/nas/cee-water/cjgleason/calval/Processed data/UMass/'"
      ],
      "text/markdown": [
       "'/nas/cee-water/cjgleason/calval/Processed data/UMass/'"
      ],
      "text/plain": [
       "[1] \"/nas/cee-water/cjgleason/calval/Processed data/UMass/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/nas/cee-water/cjgleason/calval/cnes_watermasks/fromCNES_20230724/CR/extracteo/\"\n"
     ]
    }
   ],
   "source": [
    "Sys.umask('002')\n",
    "library(dplyr)\n",
    "# library(parallel)\n",
    "library(ncdf4)\n",
    "# library(rgdal)\n",
    "# library(stringr, lib.loc = \"/nas/cee-water/cjgleason/r-lib/\",quietly = TRUE)\n",
    "library(stringr)\n",
    "library(sf)\n",
    "\n",
    "reprocess_switch=0#0 or 1. 1 means to recreate all reach and node products following some change in processing. \n",
    "#0 means to just append to existing dataframes\n",
    "process_PTs=1 # switch. do you want to deal with PTs and all downstream processing?\n",
    "process_airborne =0 #swtich\n",
    "\n",
    "# hubname='UNC'\n",
    "# rivername='WK'\n",
    "# continent='oc'\n",
    "# PT_key_file= 'SWOTCalVal_WK_KEY_20230331_20230507_1.csv' #WK\n",
    "# utm_zone='58 +south'#WK='58 +south'\n",
    "\n",
    "# hubname='UNC'\n",
    "# rivername='PY'\n",
    "# continent='na'\n",
    "# utm_zone=6 \n",
    "\n",
    "# hubname='UNC'\n",
    "# rivername='YR'\n",
    "# continent='na'\n",
    "# utm_zone=6 \n",
    "\n",
    "# hubname='UNC'\n",
    "# rivername='TN'\n",
    "# continent='na'\n",
    "# PT_key_file= 'SWOTCalVal_TN_KEY_20230717_20230825.csv' #TN\n",
    "# utm_zone=6\n",
    "\n",
    "hubname='UMass'\n",
    "rivername='CR'\n",
    "continent='na'\n",
    "PT_key_file=c('SWOTCalVal_CR_Key_20230322_20230614.csv',\n",
    "              'SWOTCalVal_CR_Key_20230516_20230613.csv', \n",
    "              'SWOTCalVal_CR_Key_20230613_20231128.csv') #CT\n",
    "utm_zone=18 #Ct= 18\n",
    "\n",
    "# hubname='UMass'\n",
    "# rivername= 'PD'\n",
    "# continent='na'\n",
    "# PT_key_file='SWOTCalVal_PD_KEY_20230723_20230903.csv'\n",
    "# utm_zone=12\n",
    "\n",
    "# hubname='UMass'\n",
    "# rivername='SG'\n",
    "# continent='na'\n",
    "# PT_key_file=c('SWOTCalVal_SG_KEY_20230624_20230831.csv',\n",
    "#               'SWOTCalVal_SG_KEY_20230628_20230704.csv') #CT\n",
    "# utm_zone=6\n",
    "\n",
    "# hubname='CU'\n",
    "# rivername='WM'\n",
    "# continent='na'\n",
    "# PT_key_file= c('SWOTCalVal_WM_KEY_20230326_20230510.csv',\n",
    "#               'SWOTCalVal_WM_KEY_20230509_20230601.csv',\n",
    "#               'SWOTCalVal_WM_KEY_20230601_20230707.csv',\n",
    "#               'SWOTCalVal_WM_KEY_20230601_20230801.csv')#WM\n",
    "# utm_zone=10 #WM= 10\n",
    "\n",
    "# hubname='Brown'\n",
    "# rivername='NS'\n",
    "# continent='na'\n",
    "# PT_key_file= 'SWOTCalVal_NS_KEY_20230525_20230613.csv' #WM\n",
    "# utm_zone=13 #NS= 13\n",
    "\n",
    "reach_end_buffer=500 #m, 'extends' the reach\n",
    "scale_maxwidth=5 # how many sword widths wide is each node box\n",
    "\n",
    "setwd(paste0('/nas/cee-water/cjgleason/calval/Processed data/',hubname,'/'))\n",
    "working_dir=(paste0('/nas/cee-water/cjgleason/calval/Processed data/',hubname,'/'))\n",
    "domain_file=paste0(rivername,'_domain.csv')\n",
    "paste0('/nas/cee-water/cjgleason/calval/Processed data/',hubname,'/')\n",
    "\n",
    "#PT paths---------\n",
    "PT_data_directory=paste0('/nas/cee-water/cjgleason/calval/xml_scripts/',hubname,'/Munged/')\n",
    "\n",
    "#--------------------------------------------------\n",
    "#drift paths------------------------------------------\n",
    "### Must change drift path to pull fromPODAACNetCDF - new small script to move them all to indiv hubs...###\n",
    "GNSS_drift_data_directory=paste0('From Andy/',hubname,'_netCDFs/')\n",
    "# GNSS_drift_data_directory='/nas/cee-water/cjgleason/calval/fromPODAACNetCDF/'\n",
    "if(reprocess_switch==1){\n",
    "    \n",
    "    drift_string= paste0('Munged drifts/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'))\n",
    "    PT_string =paste0('Munged PT/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'))\n",
    "    reachnode_string= paste0('Data frames/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'))\n",
    "    node_string =paste0('Data frames/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'),'/node')\n",
    "    reach_string=paste0('Data frames/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'),'/reach')\n",
    "    flagged_PT_output_directory=paste0('Flagged PT/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'))\n",
    "\n",
    "    directories = c(drift_string, PT_string, reachnode_string, node_string, reach_string, flagged_PT_output_directory)\n",
    "    match = paste0(\"_\",rivername,\"_\")\n",
    "    \n",
    "  # This should preserve other hub files when reprocessing one site (on the same day) in a hub that hosts multiple #\n",
    "    if (dir.exists(drift_string)){\n",
    "        for (dir in directories) {\n",
    "  # List all files in the current directory\n",
    "          file_list <- list.files(dir, full.names = TRUE)\n",
    "\n",
    "  # Filter files to keep only the ones that match the string\n",
    "          matching_files <- file_list[grep(match, file_list)]\n",
    "\n",
    "  # Delete the files\n",
    "          if (length(matching_files) > 0) {\n",
    "            file.remove(matching_files)\n",
    "            cat(rivername, \"only rerun, so deleted files in directory:\", dir, \"\\n\")\n",
    "            } \n",
    "        } \n",
    "  # Define directories if nothing was deleted  \n",
    "        QA_QC_drift_output_directory=paste0(drift_string,'/')\n",
    "        QA_QC_PT_output_directory=paste0(PT_string,'/')\n",
    "        reachnode_output_directory=paste0(reachnode_string,'/')\n",
    "        flagged_PT_output_directory=paste0(flagged_PT_output_directory,'/')\n",
    "    }\n",
    "    else {\n",
    "    # #check if we've already reprocessed today\n",
    "    # if (dir.exists(drift_string)){\n",
    "    #     #if we have, then use that as the output and clear the files in the drift directory\n",
    "    #     unlink(drift_string,recursive = TRUE)\n",
    "    #     unlink(PT_string,recursive = TRUE)\n",
    "    #     unlink(flagged_PT_output_directory,recursive = TRUE)\n",
    "    #     dir.create(drift_string)\n",
    "    #     dir.create(flagged_PT_output_directory)\n",
    "    #     dir.create(PT_string)\n",
    "    #     QA_QC_drift_output_directory=paste0(drift_string,'/')\n",
    "    #     QA_QC_PT_output_directory=paste0(PT_string,'/')\n",
    "    #     reachnode_output_directory=paste0(reachnode_string,'/')\n",
    "    #     flagged_PT_output_directory=paste0(flagged_PT_output_directory,'/')\n",
    "    #     } else {\n",
    "        #if we haven't reprocessed today\n",
    "        \n",
    "        dir.create(flagged_PT_output_directory)\n",
    "    dir.create(drift_string)\n",
    "    dir.create(PT_string)\n",
    "    dir.create(reachnode_string)\n",
    "    dir.create(node_string)\n",
    "    dir.create(reach_string)\n",
    "        \n",
    "    flagged_PT_output_directory=paste0(flagged_PT_output_directory,'/')\n",
    "    QA_QC_drift_output_directory=paste0(drift_string,'/')\n",
    "    reachnode_output_directory=paste0(reachnode_string,'/')\n",
    "    QA_QC_PT_output_directory=paste0(PT_string,'/')\n",
    "    }\n",
    "} else { #we aren't reprocessing. find the most recent folders to use\n",
    "    \n",
    "folderlist= list.files('Munged drifts',full.names = TRUE)\n",
    "    \n",
    "foldertimes=file.info(folderlist)%>%\n",
    " mutate(mintime= Sys.time()-mtime) %>%\n",
    " filter(mintime== min(mintime)) \n",
    "    \n",
    "QA_QC_drift_output_directory=paste0(row.names(foldertimes),'/')  \n",
    "    \n",
    "folderlist2= list.files('Data frames',full.names = TRUE)\n",
    "    \n",
    "foldertimes2=file.info(folderlist2)%>%\n",
    " mutate(mintime= Sys.time()-mtime) %>%\n",
    " filter(mintime== min(mintime)) \n",
    "    \n",
    "reachnode_output_directory=paste0(row.names(foldertimes2),'/')\n",
    "    \n",
    "folderlist3= list.files('Munged PT',full.names = TRUE)\n",
    "    \n",
    "foldertimes3=file.info(folderlist3)%>%\n",
    " mutate(mintime= Sys.time()-mtime) %>%\n",
    " filter(mintime== min(mintime))  \n",
    "    \n",
    "QA_QC_PT_output_directory=paste0(row.names(foldertimes3),'/') \n",
    "    \n",
    "folderlist4= list.files('Flagged PT',full.names = TRUE)\n",
    "    \n",
    "foldertimes4=file.info(folderlist4)%>%\n",
    " mutate(mintime= Sys.time()-mtime) %>%\n",
    " filter(mintime== min(mintime))  \n",
    "    \n",
    "flagged_PT_output_directory=paste0(row.names(foldertimes4),'/') \n",
    "}\n",
    "    \n",
    "flagged_drift_output_directory='Flagged drifts/'\n",
    "#--------------------------------------------------\n",
    "\n",
    "#sword paths----------------------------------------\n",
    "SWORD_path=paste0('/nas/cee-water/cjgleason/calval/SWORD_15/netcdf/',continent,\n",
    "                  '_sword_v15.nc')\n",
    "#------------------------------\n",
    "\n",
    "image_directory=paste0('/nas/cee-water/cjgleason/calval/cnes_watermasks/fromCNES_20230724/',rivername,'/extracteo/') \n",
    "print(image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "182da75d-65ee-4c19-8211-293f5b37826d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Munged drifts/reprocessed_2023_12_20/'"
      ],
      "text/latex": [
       "'Munged drifts/reprocessed\\_2023\\_12\\_20/'"
      ],
      "text/markdown": [
       "'Munged drifts/reprocessed_2023_12_20/'"
      ],
      "text/plain": [
       "[1] \"Munged drifts/reprocessed_2023_12_20/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Munged PT/reprocessed_2023_12_20/'"
      ],
      "text/latex": [
       "'Munged PT/reprocessed\\_2023\\_12\\_20/'"
      ],
      "text/markdown": [
       "'Munged PT/reprocessed_2023_12_20/'"
      ],
      "text/plain": [
       "[1] \"Munged PT/reprocessed_2023_12_20/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Data frames/reprocessed_2023_12_20/'"
      ],
      "text/latex": [
       "'Data frames/reprocessed\\_2023\\_12\\_20/'"
      ],
      "text/markdown": [
       "'Data frames/reprocessed_2023_12_20/'"
      ],
      "text/plain": [
       "[1] \"Data frames/reprocessed_2023_12_20/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Flagged PT/reprocessed_2023_12_20/'"
      ],
      "text/latex": [
       "'Flagged PT/reprocessed\\_2023\\_12\\_20/'"
      ],
      "text/markdown": [
       "'Flagged PT/reprocessed_2023_12_20/'"
      ],
      "text/plain": [
       "[1] \"Flagged PT/reprocessed_2023_12_20/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QA_QC_drift_output_directory\n",
    "QA_QC_PT_output_directory\n",
    "reachnode_output_directory\n",
    "flagged_PT_output_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0a500b3-6c25-40ed-8c27-103dfdd433fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create dataframes from drifts---------------------------------------------------------\n",
    "# #pull filename before the .csv\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/create_GNSS_dataframe.R')\n",
    "raw_GNSS=sub( \"\\\\..*\",\"\", list.files(GNSS_drift_data_directory,recursive=TRUE))\n",
    "raw_GNSS_river=which(!is.na(do.call(rbind,lapply(raw_GNSS,str_match,rivername))))\n",
    "raw_GNSS=raw_GNSS[raw_GNSS_river]\n",
    "\n",
    "#pull filename before the second _\n",
    "QA_QC_drifts=sub( \"\\\\..*\",\"\",list.files(QA_QC_drift_output_directory))\n",
    "flagged_drifts=sub(\"\\\\..*\",\"\",list.files(flagged_drift_output_directory))\n",
    "#what raw drift data have not been munged\n",
    "unmunged_drifts=setdiff(raw_GNSS,c(flagged_drifts,QA_QC_drifts))\n",
    "\n",
    "#open the key files   \n",
    "if(rivername=='WK'){\n",
    "read_keys=function(keyfile){\n",
    "   this_key= read.csv(keyfile,stringsAsFactors=FALSE, col.names = key_col_names, na.strings = c(\"\",\"NA\",\"na\",\"NaN\", \" \"))%>%\n",
    "    mutate(keyid=keyfile)%>%\n",
    "    mutate(pt_serial=as.integer(PT_Serial))\n",
    "    }\n",
    "\n",
    "master_key= do.call(rbind,lapply(PT_key_file,read_keys))}else {master_key=NULL}\n",
    "\n",
    "for (i in 1:length(unmunged_drifts)){\n",
    "create_gnss_dataframe(unmunged_drifts[i],\n",
    "                  gnss_drift_data_directory=GNSS_drift_data_directory,\n",
    "                  output_directory=QA_QC_drift_output_directory,\n",
    "                  keyfile= master_key,\n",
    "                  rivername=  rivername,\n",
    "                naughty_bin_directory=flagged_drift_output_directory )}\n",
    "\n",
    "\n",
    "#     cl=makeCluster(44)\n",
    "\n",
    "    \n",
    "#   dummy=parLapply(cl=cl,unmunged_drifts,create_gnss_dataframe,\n",
    "#                   gnss_drift_data_directory=GNSS_drift_data_directory,\n",
    "#                   output_directory=QA_QC_drift_output_directory)\n",
    "#   stopCluster(cl)\n",
    "\n",
    "\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49c8392f-a41e-45b2-b7ff-44ee82a8e49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Key file column names are of equal length\"\n",
      "[1] \"Key file passes QA/QC checks\"\n",
      "[1] \"20230406T121431_20230406T194618\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "object has no named columns; assuming order is lon then lat\n",
      "\n",
      "object has no named columns; assuming order is lon then lat\n",
      "\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'pt_time_UTC'. You can override using the\n",
      "`.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'pt_time_UTC'. You can override using the\n",
      "`.groups` argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"SWOTCalVal_CR_PT_L1_PT003_20230402T000000_20230605T183000_20230628T160754_SWOTCalVal_CR_Key_20230322_20230614.csv\"\n",
      "[1] \"this file passed all checks\"\n",
      "[1] \"20230608T125755_20230608T205604\"\n",
      "[1] \"20231116T133322_20231116T213255\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "object has no named columns; assuming order is lon then lat\n",
      "\n",
      "object has no named columns; assuming order is lon then lat\n",
      "\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'pt_time_UTC'. You can override using the\n",
      "`.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'pt_time_UTC'. You can override using the\n",
      "`.groups` argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"SWOTCalVal_CR_PT_L1_PT003_20230608T161500_20231118T203000_20231220T155847_SWOTCalVal_CR_Key_20230613_20231128.csv\"\n",
      "[1] \"this file passed all checks\"\n"
     ]
    }
   ],
   "source": [
    "#munge PTs if needed------\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/correct_PT_to_GNSS_multikey.R')\n",
    "if (process_PTs==1){\n",
    "dist_thresh=150 # 150m\n",
    "time_thresh= 15*60 #minutes as seconds, centered, so 15 =30 mins total time\n",
    "GNSS_sd_thresh=0.15 # 15cm how much variance do you want in the GNSS data when it is within the distance threshold?\n",
    "offset_sd_thresh=0.10 #m, so 10cm. the the PT apparantly shift by more than a cm?\n",
    "change_thresh_15_min=0.15#m- does it change more than 5cm in 15 minutes? that is a discontinuity in offset\n",
    "dry_threshold = 0.10 #This is a raw pt level where anything below is considered a PT out of water - this can change if we want\n",
    "#first, move .csv files with an 'L1' in them over to the PT_data_directory\n",
    "munged_files= list.files(PT_data_directory,\n",
    "                         recursive= TRUE)\n",
    "    \n",
    "PT_index=which(!is.na(do.call(rbind,lapply(munged_files,str_match,'PT_L1'))))\n",
    "PT_files=munged_files[PT_index]\n",
    "csv_index=which(!is.na(do.call(rbind,lapply(PT_files,str_match,'.csv'))))\n",
    "raw_PT_files=PT_files[csv_index]\n",
    "\n",
    "#open the key files   - Taylor added column labels and way to handle blank cells to make as NA\n",
    "\n",
    "read_keys=function(keyfile){\n",
    "    \n",
    "    # Read in key file and check column names and NODE ID for precision lost with scientific notation #\n",
    "  this_key= read.csv(keyfile,stringsAsFactors=FALSE, na.strings = c(\"\",\"NA\",\"na\",\"NaN\", \" \"))%>%\n",
    "    mutate(keyid=keyfile)%>%\n",
    "    mutate(pt_serial=as.integer(PT_Serial))\n",
    "    \n",
    "    }\n",
    "    \n",
    "master_key= do.call(rbind,lapply(PT_key_file,read_keys))\n",
    "    # key_file column names to check against (keyfile and pt_serial are added in this process, do not add to original key files)#\n",
    "key_col_names = c(\"PT_Serial\", \"Label\", \"Baro_Comp\", \"Node_ID\", \"Reach_ID\", \"US_Reach_ID\", \n",
    "                      \"DS_Reach_ID\", \"Lat_WGS84\", \"Long_WGS84\", \"Install_method\",\n",
    "                      \"Date_PT_Install\", \"Time_PT_Install_UTC\", \"Date_PT_Uninstall\",\n",
    "                      \"Time_PT_Uninstall_UTC\", \"Date_GNSS_Install\", \"Time_GNSS_Install_Start_UTC\", \n",
    "                      \"Time_GNSS_Install_End_UTC\", \"GNSS_Offset_m\", \"Receiver_Install\", \"Original_Install_Log_File\", \n",
    "                      \"Final_Install_Log_File\", \"Date_GNSS_Uninstall\", \"Time_GNSS_Uninstall_Start_UTC\", \n",
    "                      \"Time_GNSS_Uninstall_End_UTC\", \"Receiver_Uninstall\", \"Original_Uninstall_Log_File\", \"Final_Uninstall_Log_File\",\n",
    "                      \"keyid\", \"pt_serial\")\n",
    "hub_key_colnames = colnames(master_key)\n",
    "\n",
    "key_check <- function(key_col_names, hub_key_colnames){\n",
    "  if(length(key_col_names) == length(hub_key_colnames)) {\n",
    "    print('Key file column names are of equal length')\n",
    "  }\n",
    "  if(length(which(is.na(match(key_col_names,hub_key_colnames))))!=0) {\n",
    "    stop(paste('Key file has a missing/misnamed column',which(is.na(match(key_col_names,hub_key_colnames))),\",\",\n",
    "               key_col_names[!key_col_names %in% hub_key_colnames],\", please fix and reupload, and/or the Key file has an extra/misnamed column\",\n",
    "               which(is.na(match(hub_key_colnames,key_col_names))),\",\", hub_key_colnames[!hub_key_colnames %in% key_col_names],\", please fix and reupload\"))\n",
    "  }\n",
    "  if(length(unique(master_key$Node_ID))<=2){stop(\"Check that node ID in key file did not lose precision with scientific notation, if so, fix key and reupload.\")}\n",
    "    else{print(\"Key file passes QA/QC checks\")}\n",
    "}\n",
    "\n",
    "key_check(key_col_names,hub_key_colnames)\n",
    " \n",
    "#three key info here-\n",
    "    #1 PTs in the key\n",
    "    #2 unmunged PTs\n",
    "    #3 QA QC PTs\n",
    "    #4 flagged PTs\n",
    "    \n",
    "    #3 + 4 are processed files\n",
    "    \n",
    "getit_processed=function(inputstring){   \n",
    "    output=paste(strsplit(inputstring,'_')[[1]][1:8],collapse='_')\n",
    "    output=sub(\"\\\\..*\",\"\",output)\n",
    "}\n",
    "\n",
    "getit_key =function(inputstring){   \n",
    "    output=paste(c('SWOTCalVal',rivername,'PT','L1',inputstring),collapse='_')\n",
    "    output=sub(\"\\\\..*\",\"\",output)\n",
    "}\n",
    "  \n",
    "getit_negative=function(longstring, shortstrings){\n",
    "    #search for a pattern between one and many strings with partial matches allows\n",
    "        output=!any(str_detect(longstring,shortstrings)  )\n",
    "}\n",
    "    \n",
    "getit_positive=function(longstring, shortstrings){\n",
    "    #search for a pattern between one and many strings with partial matches allows\n",
    "        output=any(str_detect(longstring,shortstrings))  \n",
    "}\n",
    "       \n",
    "processed_files= do.call(rbind,lapply(c(list.files(QA_QC_PT_output_directory),list.files(flagged_PT_output_directory)),getit_processed))\n",
    "key_files=do.call(rbind,lapply(master_key$Label,getit_key))\n",
    "    \n",
    "    if (is.null(processed_files)){unprocessed_files=raw_PT_files}else{\n",
    "unprocessed_files=raw_PT_files[do.call(rbind,lapply(raw_PT_files,getit_negative,processed_files))]}\n",
    "in_key_unprocessed=unprocessed_files[do.call(rbind,lapply(unprocessed_files,getit_positive,key_files))]\n",
    "\n",
    "# print('raw')\n",
    "# print(raw_PT_files)\n",
    "# print('processed')\n",
    "# print(processed_files)\n",
    "# print('unprocessed')\n",
    "# print(unprocessed_files)\n",
    "# print('unprocessed in key')\n",
    "\n",
    "for(thisone in in_key_unprocessed){\n",
    "\n",
    "        correct_pt_to_gnss_multikey(thisone,\n",
    "                  master_key=master_key,\n",
    "                  dist_thresh=dist_thresh,\n",
    "                  time_thresh=time_thresh,\n",
    "                  pt_data_directory=PT_data_directory,\n",
    "                  gnss_drift_data_directory=QA_QC_drift_output_directory,\n",
    "                  QA_QC_pt_output_directory=QA_QC_PT_output_directory,\n",
    "                  flagged_pt_output_directory=flagged_PT_output_directory,\n",
    "                  gnss_sd_thresh=GNSS_sd_thresh,\n",
    "                  offset_sd_thresh=offset_sd_thresh,\n",
    "                  change_thresh_15_min=change_thresh_15_min) \n",
    "    \n",
    " \n",
    "}\n",
    "      \n",
    "    \n",
    "#       cl=makeCluster(20,type='FORK')\n",
    "#   dummy=parLapply(cl, in_key_unprocessed,correct_pt_to_gnss_multikey,\n",
    "#                    master_key=master_key,\n",
    "                  # dist_thresh=dist_thresh,\n",
    "                  # time_thresh=time_thresh,\n",
    "                  # pt_data_directory=PT_data_directory,\n",
    "                  # gnss_drift_data_directory=QA_QC_drift_output_directory,\n",
    "                  # QA_QC_pt_output_directory=QA_QC_PT_output_directory,\n",
    "                  # flagged_pt_output_directory=flagged_PT_output_directory,\n",
    "                  # gnss_sd_thresh=GNSS_sd_thresh,\n",
    "                  # offset_sd_thresh=offset_sd_thresh,\n",
    "                  # change_thresh_15_min=change_thresh_15_min) \n",
    "#   stopCluster(cl)\n",
    "    \n",
    "    \n",
    "    }#end if process PT\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09904c-7a23-4b54-9cf8-639f36052b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17f756bb-48ed-4423-b691-8514b2fbda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate slopes and heights from drifts within nodes and reaches------\n",
    "# reprocess_switch=1\n",
    "SWORD_reach= read.csv(domain_file)\n",
    "this_river_reach_IDs= as.numeric(unique(SWORD_reach$Reach_ID[!is.na(SWORD_reach$Reach_ID)]))\n",
    "this_river_node_IDs= as.numeric(unique(SWORD_reach$Node_ID[!is.na(SWORD_reach$Node_ID)]))\n",
    "\n",
    "\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/calculate_slope_wse_fromdrift.R')\n",
    "\n",
    "\n",
    "dummy=calculate_slope_wse_fromdrift(SWORD_path=SWORD_path,\n",
    "                                    drift_directory=QA_QC_drift_output_directory,\n",
    "                                    PT_directory=PT_directory,\n",
    "                                    output_directory=reachnode_output_directory,\n",
    "                                    this_river_reach_ids=this_river_reach_IDs,\n",
    "                                    this_river_node_ids=this_river_node_IDs,\n",
    "                                    utm_zone=utm_zone, \n",
    "                                    buffer=reach_end_buffer,\n",
    "                                    rivername=rivername,\n",
    "                                    reprocess_switch=reprocess_switch,\n",
    "                                    core_count=core_count,\n",
    "                                    scale_maxwidth=scale_maxwidth)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d0d19-7b36-450b-8b81-6baa8703b8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890aff5-392c-4000-a3df-07fc5b3e1326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de238d52-ab26-450a-8aff-8d85e157f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'node_id', 'pt_time_UTC'. You can override\n",
      "using the `.groups` argument.\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "\u001b[1m\u001b[33mError\u001b[39m in `dplyr::select()`:\u001b[22m\n\u001b[33m!\u001b[39m Can't subset columns that don't exist.\n\u001b[31m✖\u001b[39m Column `Node_ID` doesn't exist.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[33mError\u001b[39m in `dplyr::select()`:\u001b[22m\n\u001b[33m!\u001b[39m Can't subset columns that don't exist.\n\u001b[31m✖\u001b[39m Column `Node_ID` doesn't exist.\nTraceback:\n",
      "1. calculate_slope_wse_fromPT(keyfile = master_key, pt_files = PT_files, \n .     SWORD_path = SWORD_path, SWORD_reach = SWORD_reach, this_river_reach_ids = this_river_reach_IDs, \n .     this_river_node_ids = this_river_node_IDs, rivername = rivername, \n .     output_directory = reachnode_output_directory, alongstream_error = alongstream_error, \n .     crossstream_error = crossstream_error, measurement_error = measurement_error)   # at line 31-41 of file <text>",
      "2. lapply(pt_files, run_nodes, key_df = key_df, measurement_error = measurement_error, \n .     alongstream_error = alongstream_error, crossstream_error = crossstream_error, \n .     node_dist_df = node_dist_df)",
      "3. FUN(X[[i]], ...)",
      "4. read.csv(pt_file) %>% dplyr::select(pt_serial, pt_time_UTC, pt_wse, \n .     pt_wse_sd, sigma_pt_correction_m, Node_ID, flag) %>% mutate(pt_id = paste0(pt_serial, \n .     \"_\", Node_ID)) %>% left_join(key_df, by = \"pt_id\", relationship = \"many-to-many\")",
      "5. left_join(., key_df, by = \"pt_id\", relationship = \"many-to-many\")",
      "6. mutate(., pt_id = paste0(pt_serial, \"_\", Node_ID))",
      "7. dplyr::select(., pt_serial, pt_time_UTC, pt_wse, pt_wse_sd, sigma_pt_correction_m, \n .     Node_ID, flag)",
      "8. select.data.frame(., pt_serial, pt_time_UTC, pt_wse, pt_wse_sd, \n .     sigma_pt_correction_m, Node_ID, flag)",
      "9. tidyselect::eval_select(expr(c(...)), data = .data, error_call = error_call)",
      "10. eval_select_impl(data, names(data), as_quosure(expr, env), include = include, \n  .     exclude = exclude, strict = strict, name_spec = name_spec, \n  .     allow_rename = allow_rename, allow_empty = allow_empty, allow_predicates = allow_predicates, \n  .     error_call = error_call, )",
      "11. with_subscript_errors(out <- vars_select_eval(vars, expr, strict = strict, \n  .     data = x, name_spec = name_spec, uniquely_named = uniquely_named, \n  .     allow_rename = allow_rename, allow_empty = allow_empty, allow_predicates = allow_predicates, \n  .     type = type, error_call = error_call), type = type)",
      "12. try_fetch(expr, vctrs_error_subscript = function(cnd) {\n  .     cnd$subscript_action <- subscript_action(type)\n  .     cnd$subscript_elt <- \"column\"\n  .     cnd_signal(cnd)\n  . })",
      "13. withCallingHandlers(expr, condition = function(cnd) {\n  .     {\n  .         .__handler_frame__. <- TRUE\n  .         .__setup_frame__. <- frame\n  .         if (inherits(cnd, \"message\")) {\n  .             except <- c(\"warning\", \"error\")\n  .         }\n  .         else if (inherits(cnd, \"warning\")) {\n  .             except <- \"error\"\n  .         }\n  .         else {\n  .             except <- \"\"\n  .         }\n  .     }\n  .     while (!is_null(cnd)) {\n  .         if (inherits(cnd, \"vctrs_error_subscript\")) {\n  .             out <- handlers[[1L]](cnd)\n  .             if (!inherits(out, \"rlang_zap\")) \n  .                 throw(out)\n  .         }\n  .         inherit <- .subset2(.subset2(cnd, \"rlang\"), \"inherit\")\n  .         if (is_false(inherit)) {\n  .             return()\n  .         }\n  .         cnd <- .subset2(cnd, \"parent\")\n  .     }\n  . })",
      "14. vars_select_eval(vars, expr, strict = strict, data = x, name_spec = name_spec, \n  .     uniquely_named = uniquely_named, allow_rename = allow_rename, \n  .     allow_empty = allow_empty, allow_predicates = allow_predicates, \n  .     type = type, error_call = error_call)",
      "15. walk_data_tree(expr, data_mask, context_mask)",
      "16. eval_c(expr, data_mask, context_mask)",
      "17. reduce_sels(node, data_mask, context_mask, init = init)",
      "18. walk_data_tree(new, data_mask, context_mask)",
      "19. as_indices_sel_impl(out, vars = vars, strict = strict, data = data, \n  .     allow_predicates = allow_predicates, call = error_call, arg = as_label(expr))",
      "20. as_indices_impl(x, vars, call = call, arg = arg, strict = strict)",
      "21. chr_as_locations(x, vars, call = call, arg = arg)",
      "22. vctrs::vec_as_location(x, n = length(vars), names = vars, call = call, \n  .     arg = arg)",
      "23. (function () \n  . stop_subscript_oob(i = i, subscript_type = subscript_type, names = names, \n  .     subscript_action = subscript_action, subscript_arg = subscript_arg, \n  .     call = call))()",
      "24. stop_subscript_oob(i = i, subscript_type = subscript_type, names = names, \n  .     subscript_action = subscript_action, subscript_arg = subscript_arg, \n  .     call = call)",
      "25. stop_subscript(class = \"vctrs_error_subscript_oob\", i = i, subscript_type = subscript_type, \n  .     ..., call = call)",
      "26. abort(class = c(class, \"vctrs_error_subscript\"), i = i, ..., \n  .     call = call)",
      "27. signal_abort(cnd, .file)",
      "28. signalCondition(cnd)",
      "29. (function (cnd) \n  . {\n  .     {\n  .         .__handler_frame__. <- TRUE\n  .         .__setup_frame__. <- frame\n  .         if (inherits(cnd, \"message\")) {\n  .             except <- c(\"warning\", \"error\")\n  .         }\n  .         else if (inherits(cnd, \"warning\")) {\n  .             except <- \"error\"\n  .         }\n  .         else {\n  .             except <- \"\"\n  .         }\n  .     }\n  .     while (!is_null(cnd)) {\n  .         if (inherits(cnd, \"vctrs_error_subscript\")) {\n  .             out <- handlers[[1L]](cnd)\n  .             if (!inherits(out, \"rlang_zap\")) \n  .                 throw(out)\n  .         }\n  .         inherit <- .subset2(.subset2(cnd, \"rlang\"), \"inherit\")\n  .         if (is_false(inherit)) {\n  .             return()\n  .         }\n  .         cnd <- .subset2(cnd, \"parent\")\n  .     }\n  . })(structure(list(message = \"\", trace = structure(list(call = list(\n  .     IRkernel::main(), kernel$run(), handle_shell(), executor$execute(msg), \n  .     tryCatch(evaluate(request$content$code, envir = .GlobalEnv, \n  .         output_handler = oh, stop_on_error = 1L), interrupt = function(cond) {\n  .         log_debug(\"Interrupt during execution\")\n  .         interrupted <<- TRUE\n  .     }, error = .self$handle_error), tryCatchList(expr, classes, \n  .         parentenv, handlers), tryCatchOne(tryCatchList(expr, \n  .         names[-nh], parentenv, handlers[-nh]), names[nh], parentenv, \n  .         handlers[[nh]]), doTryCatch(return(expr), name, parentenv, \n  .         handler), tryCatchList(expr, names[-nh], parentenv, handlers[-nh]), \n  .     tryCatchOne(expr, names, parentenv, handlers[[1L]]), doTryCatch(return(expr), \n  .         name, parentenv, handler), evaluate(request$content$code, \n  .         envir = .GlobalEnv, output_handler = oh, stop_on_error = 1L), \n  .     evaluate_call(expr, parsed$src[[i]], envir = envir, enclos = enclos, \n  .         debug = debug, last = i == length(out), use_try = stop_on_error != \n  .             2L, keep_warning = keep_warning, keep_message = keep_message, \n  .         log_echo = log_echo, log_warning = log_warning, output_handler = output_handler, \n  .         include_timing = include_timing), timing_fn(handle(ev <- withCallingHandlers(withVisible(eval_with_user_handlers(expr, \n  .         envir, enclos, user_handlers)), warning = wHandler, error = eHandler, \n  .         message = mHandler))), handle(ev <- withCallingHandlers(withVisible(eval_with_user_handlers(expr, \n  .         envir, enclos, user_handlers)), warning = wHandler, error = eHandler, \n  .         message = mHandler)), try(f, silent = TRUE), tryCatch(expr, \n  .         error = function(e) {\n  .             call <- conditionCall(e)\n  .             if (!is.null(call)) {\n  .                 if (identical(call[[1L]], quote(doTryCatch))) \n  .                   call <- sys.call(-4L)\n  .                 dcall <- deparse(call, nlines = 1L)\n  .                 prefix <- paste(\"Error in\", dcall, \": \")\n  .                 LONG <- 75L\n  .                 sm <- strsplit(conditionMessage(e), \"\\n\")[[1L]]\n  .                 w <- 14L + nchar(dcall, type = \"w\") + nchar(sm[1L], \n  .                   type = \"w\")\n  .                 if (is.na(w)) \n  .                   w <- 14L + nchar(dcall, type = \"b\") + nchar(sm[1L], \n  .                     type = \"b\")\n  .                 if (w > LONG) \n  .                   prefix <- paste0(prefix, \"\\n  \")\n  .             }\n  .             else prefix <- \"Error : \"\n  .             msg <- paste0(prefix, conditionMessage(e), \"\\n\")\n  .             .Internal(seterrmessage(msg[1L]))\n  .             if (!silent && isTRUE(getOption(\"show.error.messages\"))) {\n  .                 cat(msg, file = outFile)\n  .                 .Internal(printDeferredWarnings())\n  .             }\n  .             invisible(structure(msg, class = \"try-error\", condition = e))\n  .         }), tryCatchList(expr, classes, parentenv, handlers), \n  .     tryCatchOne(expr, names, parentenv, handlers[[1L]]), doTryCatch(return(expr), \n  .         name, parentenv, handler), withCallingHandlers(withVisible(eval_with_user_handlers(expr, \n  .         envir, enclos, user_handlers)), warning = wHandler, error = eHandler, \n  .         message = mHandler), withVisible(eval_with_user_handlers(expr, \n  .         envir, enclos, user_handlers)), eval_with_user_handlers(expr, \n  .         envir, enclos, user_handlers), eval(expr, envir, enclos), \n  .     eval(expr, envir, enclos), calculate_slope_wse_fromPT(keyfile = master_key, \n  .         pt_files = PT_files, SWORD_path = SWORD_path, SWORD_reach = SWORD_reach, \n  .         this_river_reach_ids = this_river_reach_IDs, this_river_node_ids = this_river_node_IDs, \n  .         rivername = rivername, output_directory = reachnode_output_directory, \n  .         alongstream_error = alongstream_error, crossstream_error = crossstream_error, \n  .         measurement_error = measurement_error), lapply(pt_files, \n  .         run_nodes, key_df = key_df, measurement_error = measurement_error, \n  .         alongstream_error = alongstream_error, crossstream_error = crossstream_error, \n  .         node_dist_df = node_dist_df), FUN(X[[i]], ...), read.csv(pt_file) %>% \n  .         dplyr::select(pt_serial, pt_time_UTC, pt_wse, pt_wse_sd, \n  .             sigma_pt_correction_m, Node_ID, flag) %>% mutate(pt_id = paste0(pt_serial, \n  .         \"_\", Node_ID)) %>% left_join(key_df, by = \"pt_id\", relationship = \"many-to-many\"), \n  .     left_join(., key_df, by = \"pt_id\", relationship = \"many-to-many\"), \n  .     mutate(., pt_id = paste0(pt_serial, \"_\", Node_ID)), dplyr::select(., \n  .         pt_serial, pt_time_UTC, pt_wse, pt_wse_sd, sigma_pt_correction_m, \n  .         Node_ID, flag), select.data.frame(., pt_serial, pt_time_UTC, \n  .         pt_wse, pt_wse_sd, sigma_pt_correction_m, Node_ID, flag), \n  .     tidyselect::eval_select(expr(c(...)), data = .data, error_call = error_call), \n  .     eval_select_impl(data, names(data), as_quosure(expr, env), \n  .         include = include, exclude = exclude, strict = strict, \n  .         name_spec = name_spec, allow_rename = allow_rename, allow_empty = allow_empty, \n  .         allow_predicates = allow_predicates, error_call = error_call, \n  .         ), with_subscript_errors(out <- vars_select_eval(vars, \n  .         expr, strict = strict, data = x, name_spec = name_spec, \n  .         uniquely_named = uniquely_named, allow_rename = allow_rename, \n  .         allow_empty = allow_empty, allow_predicates = allow_predicates, \n  .         type = type, error_call = error_call), type = type), \n  .     try_fetch(expr, vctrs_error_subscript = function(cnd) {\n  .         cnd$subscript_action <- subscript_action(type)\n  .         cnd$subscript_elt <- \"column\"\n  .         cnd_signal(cnd)\n  .     }), withCallingHandlers(expr, condition = function(cnd) {\n  .         {\n  .             .__handler_frame__. <- TRUE\n  .             .__setup_frame__. <- frame\n  .             if (inherits(cnd, \"message\")) {\n  .                 except <- c(\"warning\", \"error\")\n  .             }\n  .             else if (inherits(cnd, \"warning\")) {\n  .                 except <- \"error\"\n  .             }\n  .             else {\n  .                 except <- \"\"\n  .             }\n  .         }\n  .         while (!is_null(cnd)) {\n  .             if (inherits(cnd, \"vctrs_error_subscript\")) {\n  .                 out <- handlers[[1L]](cnd)\n  .                 if (!inherits(out, \"rlang_zap\")) \n  .                   throw(out)\n  .             }\n  .             inherit <- .subset2(.subset2(cnd, \"rlang\"), \"inherit\")\n  .             if (is_false(inherit)) {\n  .                 return()\n  .             }\n  .             cnd <- .subset2(cnd, \"parent\")\n  .         }\n  .     }), vars_select_eval(vars, expr, strict = strict, data = x, \n  .         name_spec = name_spec, uniquely_named = uniquely_named, \n  .         allow_rename = allow_rename, allow_empty = allow_empty, \n  .         allow_predicates = allow_predicates, type = type, error_call = error_call), \n  .     walk_data_tree(expr, data_mask, context_mask), eval_c(expr, \n  .         data_mask, context_mask), reduce_sels(node, data_mask, \n  .         context_mask, init = init), walk_data_tree(new, data_mask, \n  .         context_mask), as_indices_sel_impl(out, vars = vars, \n  .         strict = strict, data = data, allow_predicates = allow_predicates, \n  .         call = error_call, arg = as_label(expr)), as_indices_impl(x, \n  .         vars, call = call, arg = arg, strict = strict), chr_as_locations(x, \n  .         vars, call = call, arg = arg), vctrs::vec_as_location(x, \n  .         n = length(vars), names = vars, call = call, arg = arg), \n  .     `<fn>`(), stop_subscript_oob(i = i, subscript_type = subscript_type, \n  .         names = names, subscript_action = subscript_action, subscript_arg = subscript_arg, \n  .         call = call), stop_subscript(class = \"vctrs_error_subscript_oob\", \n  .         i = i, subscript_type = subscript_type, ..., call = call), \n  .     abort(class = c(class, \"vctrs_error_subscript\"), i = i, ..., \n  .         call = call)), parent = c(0L, 1L, 2L, 3L, 4L, 5L, 6L, \n  . 7L, 6L, 9L, 10L, 4L, 12L, 13L, 13L, 15L, 16L, 17L, 18L, 19L, \n  . 13L, 13L, 13L, 23L, 24L, 0L, 26L, 27L, 28L, 0L, 0L, 0L, 0L, 33L, \n  . 34L, 35L, 36L, 37L, 35L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, \n  . 0L, 48L, 49L, 50L), visible = c(TRUE, TRUE, TRUE, TRUE, TRUE, \n  . TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, \n  . TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, \n  . TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, \n  . FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n  . FALSE, FALSE, FALSE, FALSE, FALSE), namespace = c(\"IRkernel\", \n  . NA, \"IRkernel\", NA, \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \n  . \"base\", \"evaluate\", \"evaluate\", \"evaluate\", \"evaluate\", \"base\", \n  . \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"evaluate\", \"base\", \n  . \"base\", NA, \"base\", NA, NA, \"dplyr\", \"dplyr\", \"dplyr\", \"dplyr\", \n  . \"tidyselect\", \"tidyselect\", \"tidyselect\", \"rlang\", \"base\", \"tidyselect\", \n  . \"tidyselect\", \"tidyselect\", \"tidyselect\", \"tidyselect\", \"tidyselect\", \n  . \"tidyselect\", \"tidyselect\", \"vctrs\", \"vctrs\", \"vctrs\", \"vctrs\", \n  . \"rlang\"), scope = c(\"::\", NA, \"local\", NA, \"::\", \"local\", \"local\", \n  . \"local\", \"local\", \"local\", \"local\", \"::\", \":::\", \"local\", \"local\", \n  . \"::\", \"::\", \"local\", \"local\", \"local\", \"::\", \"::\", \":::\", \"::\", \n  . \"::\", \"global\", \"::\", NA, NA, \"::\", \"::\", \"::\", \":::\", \"::\", \n  . \":::\", \":::\", \"::\", \"::\", \":::\", \":::\", \":::\", \":::\", \":::\", \n  . \":::\", \":::\", \":::\", \"::\", \"local\", \":::\", \":::\", \"::\"), error_frame = c(FALSE, \n  . FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n  . FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n  . FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n  . FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, \n  . FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n  . FALSE, FALSE, FALSE, FALSE, FALSE)), row.names = c(NA, -51L), version = 2L, class = c(\"rlang_trace\", \n  . \"rlib_trace\", \"tbl\", \"data.frame\")), parent = NULL, i = \"Node_ID\", \n  .     subscript_type = \"character\", names = c(\"pt_time_UTC\", \"pt_lat\", \n  .     \"pt_lon\", \"pt_install_UTC\", \"pt_uninstall_UTC\", \"gnss_install_UTC\", \n  .     \"gnss_uninstall_UTC\", \"install_method\", \"pt_serial\", \"pt_level\", \n  .     \"temperature\", \"driftID_install\", \"driftID_uninstall\", \"datetime\", \n  .     \"keyid\", \"Date_GNSS_Install\", \"Date_GNSS_Uninstall\", \"Reach_ID\", \n  .     \"ping_time_UTC\", \"pt_correction\", \"pt_wse_sd\", \"pt_wse\", \n  .     \"sigma_pt_correction_m\", \"flag\"), subscript_action = NULL, \n  .     subscript_arg = \"Node_ID\", rlang = list(inherit = TRUE), \n  .     call = dplyr::select(., pt_serial, pt_time_UTC, pt_wse, pt_wse_sd, \n  .         sigma_pt_correction_m, Node_ID, flag)), class = c(\"vctrs_error_subscript_oob\", \n  . \"vctrs_error_subscript\", \"rlang_error\", \"error\", \"condition\")))",
      "30. handlers[[1L]](cnd)",
      "31. cnd_signal(cnd)",
      "32. signal_abort(cnd)"
     ]
    }
   ],
   "source": [
    "#calculate slopes and heights from PTs within nodes and reaches----\n",
    "if (process_PTs==1){\n",
    "PT_files=paste0(QA_QC_PT_output_directory,list.files(QA_QC_PT_output_directory))\n",
    "\n",
    "# PT_files = list(\"Munged PT/reprocessed_2023_12_20/SWOTCalVal_CR_PT_L1_PT003_20230402T000000_20230605T183000_20230628T160754_SWOTCalVal_CR_Key_20230322_20230614.csv\",\n",
    "                #\"Munged PT/reprocessed_2023_12_20/SWOTCalVal_CR_PT_L1_PT003_20230608T161500_20231118T203000_20231220T155847_SWOTCalVal_CR_Key_20230613_20231128.csv\")\n",
    "SWORD_reach= read.csv(domain_file)\n",
    "this_river_reach_IDs= as.numeric(as.character(unique(SWORD_reach$Reach_ID)))\n",
    "this_river_node_IDs= as.numeric(unique(SWORD_reach$Node_ID[!is.na(SWORD_reach$Node_ID)]))\n",
    " \n",
    "alongstream_error= 0.0001*200 #m error we get from the downstream slope of a reach in a node. This placeholder is a 1e-4 slope over a 200m node\n",
    "crossstream_error= 0.005 #m error we get from PT not representing cross stream superelevation/noise in a node\n",
    "measurement_error= 0.001 #m error we get from PT measurement itself \n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/calculate_slope_wse_fromPT.R')\n",
    "\n",
    "read_keys=function(keyfile){\n",
    "   key_col_names = c(\"PT_Serial\", \"Label\", \"Baro_Comp\", \"Node_ID\", \"Reach_ID\", \"US_Reach_ID\", \n",
    "                      \"DS_Reach_ID\", \"Lat_WGS84\", \"Long_WGS84\", \"Install_method\",\n",
    "                      \"Date_PT_Install\", \"Time_PT_Install_UTC\", \"Date_PT_Uninstall\",\n",
    "                      \"Time_PT_Uninstall_UTC\", \"Date_GNSS_Install\", \"Time_GNSS_Install_Start_UTC\", \n",
    "                      \"Time_GNSS_Install_End_UTC\", \"GNSS_Offset_m\", \"Receiver_Install\", \"Original_Install_Log_File\", \n",
    "                      \"Final_Install_Log_File\", \"Date_GNSS_Uninstall\", \"Time_GNSS_Uninstall_Start_UTC\", \n",
    "                      \"Time_GNSS_Uninstall_End_UTC\", \"Receiver_Uninstall\", \"Original_Uninstall_Log_File\", \"Final_Uninstall_Log_File\")\n",
    "   this_key= read.csv(keyfile,stringsAsFactors=FALSE, col.names = key_col_names, na.strings = c(\"\",\"NA\",\"na\",\"NaN\", \" \"))%>%\n",
    "    mutate(keyid=keyfile)%>%\n",
    "    mutate(pt_serial=as.integer(PT_Serial))\n",
    "    }\n",
    "    \n",
    "master_key= do.call(rbind,lapply(PT_key_file,read_keys))\n",
    "\n",
    "dummy=calculate_slope_wse_fromPT(keyfile=master_key,\n",
    "                                 pt_files=PT_files,\n",
    "                                 SWORD_path=SWORD_path,\n",
    "                                 SWORD_reach=SWORD_reach,\n",
    "                                 this_river_reach_ids=this_river_reach_IDs,\n",
    "                                 this_river_node_ids=this_river_node_IDs,\n",
    "                                 rivername=rivername,\n",
    "                                 output_directory= reachnode_output_directory,\n",
    "                                 alongstream_error=alongstream_error,\n",
    "                                 crossstream_error=crossstream_error,\n",
    "                                 measurement_error=measurement_error)\n",
    "     }\n",
    "#-----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a92fb3-131a-40d6-bd24-e67abd5bf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define what drift goes with what SWOT overpass--------------------\n",
    "#SWOT_L2_HR_RiverSP_<FileIdentifier>_<CycleID>_<PassID>_<ContinentID>_<RangeBeginningDateTime>_<RangeEndingDateTime>_<CRID>_<ProductCounter>.<extension> \n",
    "\n",
    "if (process_PTs ==1){\n",
    "passfile=paste0('/nas/cee-water/cjgleason/calval/Processed data/riversp_list_clean_',rivername,'_20231102.txt')\n",
    "\n",
    " \n",
    "passnames=read.delim(passfile,header=F)$V1\n",
    " \n",
    "  \n",
    "time_threshold_sec= 120*60 #two hour\n",
    "wse_threshold_m=0.05 #within 5cm\n",
    "distance_threshold_m =200 #within 200m\n",
    "\n",
    "if (!dir.exists(paste0('Matched_drifts/','processed_',str_replace_all(as.character(Sys.Date()),'\\\\-','_')))){\n",
    "    dir.create(paste0('Matched_drifts/','processed_',str_replace_all(as.character(Sys.Date()),'\\\\-','_')))}\n",
    "\n",
    "\n",
    "matched_output_directory= paste0('Matched_drifts/','processed_',str_replace_all(as.character(Sys.Date()),'\\\\-','_'),'/')\n",
    "munged_drift_directory= QA_QC_drift_output_directory\n",
    "munged_pt_directory=paste0(working_dir,QA_QC_PT_output_directory)\n",
    "\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/select_appropriate_drift.R')\n",
    "\n",
    "read_keys=function(keyfile){\n",
    "   this_key= read.csv(keyfile,stringsAsFactors=FALSE, na.strings = c(\"\",\"NA\",\"na\",\"NaN\", \" \"))%>%\n",
    "    mutate(keyid=keyfile)%>%\n",
    "    mutate(pt_serial=as.integer(PT_Serial))\n",
    "    }\n",
    "    \n",
    "master_key= do.call(rbind,lapply(PT_key_file,read_keys))\n",
    "  \n",
    "for (i in 1:length(passnames)){\n",
    "  #  print(passnames[i])\n",
    "   select_appropriate_drift(passnames[i],\n",
    "                               drift_node_directory= paste0(reachnode_output_directory,'/node/'),\n",
    "                               munged_drift_directory=munged_drift_directory,\n",
    "                               matched_output_directory=matched_output_directory,\n",
    "                               munged_pt_directory=munged_pt_directory,\n",
    "                               time_threshold_sec=time_threshold_sec,\n",
    "                               wse_threshold_m= wse_threshold_m,\n",
    "                               distance_threshold_m=distance_threshold_m,\n",
    "                               keyfile=master_key,\n",
    "                               rivername=rivername)\n",
    "    \n",
    "    }\n",
    "\n",
    "  #too memory intensive to parallize. Need to properly paralellize via rslurm to send across the cluster \n",
    "    #rahter than a single node like this\n",
    "#    cl=makeCluster(2,  type = \"FORK\")\n",
    "# dummy=parLapply(cl, passnames,select_appropriate_drift,\n",
    "#                                drift_node_directory= paste0(reachnode_output_directory,'/node/'),\n",
    "#                                munged_drift_directory=munged_drift_directory,\n",
    "#                                matched_output_directory=matched_output_directory,\n",
    "#                                munged_pt_directory=munged_pt_directory,\n",
    "#                                time_threshold_sec=time_threshold_sec,\n",
    "#                                wse_threshold_m= wse_threshold_m,\n",
    "#                                distance_threshold_m=distance_threshold_m,\n",
    "#                                keyfile=master_key,\n",
    "#                                rivername=rivername)\n",
    "\n",
    "#  stopCluster(cl)\n",
    "    \n",
    "    }\n",
    "    \n",
    "#-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57866c3-98a0-4c72-8b0f-db48b26eca34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5155e21-63ea-4924-8a93-46b0a4a0d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcluate areas from images------------------\n",
    "if (process_airborne ==1){\n",
    "\n",
    "a=Sys.time()\n",
    "\n",
    "library(parallel)\n",
    "library(raster)\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/calculate_area_from_imagery.R')\n",
    "\n",
    "scale_maxwidth = 3\n",
    "#path of input image \n",
    "#image = '/nas/cee-water/cjgleason/calval/Processed data/Imagery/Input/BinaryMap.tif'\n",
    "\n",
    "    #make this use a rivername code\n",
    "imagelist=as.list(list.files(image_directory,full.names=TRUE))\n",
    "    \n",
    " #  print(imagelist)\n",
    "    \n",
    "#make this point to a hub\n",
    "dir_output =paste0('/nas/cee-water/cjgleason/calval/Processed data/',hubname,'/Area/')\n",
    "\n",
    "    image_reaches= unique(read.csv(domain_file)$Reach_ID)\n",
    "    image_nodes=unique(read.csv(domain_file)$Node_ID)\n",
    "    \n",
    "\n",
    "calculate_area_from_imagery(image=imagelist[[1]],\n",
    "                 this_river_reach_ids=image_reaches,\n",
    "                 this_river_node_ids=image_nodes,\n",
    "                 rivercode=rivername,\n",
    "                 utm_zone=utm_zone,\n",
    "                 scale_maxwidth=scale_maxwidth, \n",
    "                 SWORD_path=SWORD_path)\n",
    "\n",
    "# cl=makeCluster(47, type ='FORK')\n",
    "\n",
    "# dummy=parLapply(cl,  imagelist,calculate_area_from_imagery,\n",
    "#                       this_river_reach_ids=image_reaches,\n",
    "#                  this_river_node_ids=image_nodes,\n",
    "#                  rivercode=rivername,\n",
    "#                  utm_zone=utm_zone,\n",
    "#                  scale_maxwidth=scale_maxwidth, \n",
    "#                  SWORD_path=SWORD_path)\n",
    "\n",
    "# stopCluster(cl)\n",
    "    \n",
    " print(Sys.time()-a)#calcluate areas from images----\n",
    "\n",
    " }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:.conda-TaylorsToolboxes]",
   "language": "R",
   "name": "conda-env-.conda-TaylorsToolboxes-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
