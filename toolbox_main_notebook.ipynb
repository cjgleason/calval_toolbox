{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7901617d-d7e3-4675-b474-1be621886f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/nas/cee-water/cjgleason/calval/Processed data/Brown/'"
      ],
      "text/latex": [
       "'/nas/cee-water/cjgleason/calval/Processed data/Brown/'"
      ],
      "text/markdown": [
       "'/nas/cee-water/cjgleason/calval/Processed data/Brown/'"
      ],
      "text/plain": [
       "[1] \"/nas/cee-water/cjgleason/calval/Processed data/Brown/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/nas/cee-water/cjgleason/calval/cnes_watermasks/fromCNES_20230724/NS/extracteo/\"\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(parallel)\n",
    "library(stringr)\n",
    "\n",
    "reprocess_switch=0 #0 or 1. 1 means to recreate all reach and node products following some change in processing. \n",
    "#0 means to just append to existing dataframes\n",
    "process_PTs=1 # switch. do you want to deal with PTs and all downstream processing?\n",
    "process_airborne =1 #swtich\n",
    "\n",
    "# hubname='UNC'\n",
    "# rivername='WK'\n",
    "# continent='oc'\n",
    "# PT_key_file= 'SWOTCalVal_WK_KEY_20230331_20230507_1.csv' #WK\n",
    "# utm_zone='58 +south'#WK='58 +south'\n",
    "\n",
    "# hubname='UNC'\n",
    "# rivername='PY'\n",
    "# continent='na'\n",
    "# utm_zone=6 \n",
    "\n",
    "# hubname='UNC'\n",
    "# rivername='YR'\n",
    "# continent='na'\n",
    "# utm_zone=6 \n",
    "\n",
    "# hubname='UMass'\n",
    "# rivername='CR'\n",
    "# continent='na'\n",
    "# PT_key_file=c('SWOTCalVal_CR_Key_20230322_20230614.csv',\n",
    "#               'SWOTCalVal_CR_Key_20230516_20230613.csv') #CT\n",
    "# utm_zone=18 #Ct= 18\n",
    "\n",
    "# hubname='CU'\n",
    "# rivername='WM'\n",
    "# continent='na'\n",
    "# PT_key_file= c('SWOTCalVal_WM_KEY_20230326_20230510.csv',\n",
    "#                'SWOTCalVal_WM_KEY_20230509_20230601.csv')#WM\n",
    "# utm_zone=10 #WM= 10\n",
    "\n",
    "hubname='Brown'\n",
    "rivername='NS'\n",
    "continent='na'\n",
    "PT_key_file= 'SWOTCalVal_NS_KEY_20230525_20230613.csv' #WM\n",
    "utm_zone=13 #NS= 13\n",
    "\n",
    "\n",
    "reach_end_buffer=500 #m, 'extends' the reach\n",
    "\n",
    "setwd(paste0('/nas/cee-water/cjgleason/calval/Processed data/',hubname,'/'))\n",
    "working_dir=(paste0('/nas/cee-water/cjgleason/calval/Processed data/',hubname,'/'))\n",
    "domain_file=paste0(rivername,'_domain.csv')\n",
    "paste0('/nas/cee-water/cjgleason/calval/Processed data/',hubname,'/')\n",
    "\n",
    "#PT paths---------\n",
    "PT_data_directory=paste0('/nas/cee-water/cjgleason/calval/xml_scripts/',hubname,'/Munged/')\n",
    "flagged_PT_output_directory='Flagged PT/'\n",
    "#--------------------------------------------------\n",
    "#drift paths------------------------------------------\n",
    "GNSS_drift_data_directory=paste0('From Andy/',hubname,'_netCDFs/')\n",
    "if(reprocess_switch==1){\n",
    "    \n",
    "    drift_string= paste0('Munged drifts/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'))\n",
    "    PT_string =paste0('Munged PT/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'))\n",
    "    reachnode_string= paste0('Data frames/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'))\n",
    "    node_string =paste0('Data frames/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'),'/node')\n",
    "    reach_string=paste0('Data frames/','reprocessed_',  str_replace_all(as.character(Sys.Date()),'\\\\-','_'),'/reach')\n",
    "    \n",
    "    #check if we've already reprocessed today\n",
    "    if (dir.exists(drift_string)){\n",
    "        #if we have, then use that as the output and clear the files in the drift directory\n",
    "        unlink(drift_string, recursive = TRUE)\n",
    "        unlink(PT_string,recursive = TRUE)\n",
    "        dir.create(drift_string)\n",
    "        dir.create(PT_string)\n",
    "        QA_QC_drift_output_directory=paste0(drift_string,'/')\n",
    "        QA_QC_PT_output_directory=paste0(PT_string,'/')\n",
    "        reachnode_output_directory=paste0(reachnode_string,'/')\n",
    "        } else {\n",
    "        #if we haven't reprocessed today\n",
    "        \n",
    "        \n",
    "    dir.create(drift_string)\n",
    "    dir.create(PT_string)\n",
    "    dir.create(reachnode_string)\n",
    "    dir.create(node_string)\n",
    "    dir.create(reach_string)\n",
    "        \n",
    "    QA_QC_drift_output_directory=paste0(drift_string,'/')\n",
    "    reachnode_output_directory=paste0(reachnode_string,'/')\n",
    "    QA_QC_PT_output_directory=paste0(PT_string,'/')\n",
    "    }\n",
    "    \n",
    "    } else { #we aren't reprocessing. find the most recent folders to use\n",
    "    \n",
    "folderlist= list.files('Munged drifts',full.names = TRUE)\n",
    "    \n",
    "foldertimes=file.info(folderlist)%>%\n",
    " mutate(mintime= Sys.time()-mtime) %>%\n",
    " filter(mintime== min(mintime)) \n",
    "    \n",
    "QA_QC_drift_output_directory=paste0(row.names(foldertimes),'/')  \n",
    "    \n",
    "folderlist2= list.files('Data frames',full.names = TRUE)\n",
    "    \n",
    "foldertimes2=file.info(folderlist2)%>%\n",
    " mutate(mintime= Sys.time()-mtime) %>%\n",
    " filter(mintime== min(mintime)) \n",
    "    \n",
    "reachnode_output_directory=paste0(row.names(foldertimes2),'/')\n",
    "    \n",
    "folderlist3= list.files('Munged PT',full.names = TRUE)\n",
    "    \n",
    "foldertimes3=file.info(folderlist3)%>%\n",
    " mutate(mintime= Sys.time()-mtime) %>%\n",
    " filter(mintime== min(mintime))  \n",
    "    \n",
    "QA_QC_PT_output_directory=paste0(row.names(foldertimes3),'/') \n",
    "}\n",
    "\n",
    "flagged_drift_output_directory='Flagged drifts/'\n",
    "#--------------------------------------------------\n",
    "\n",
    "#sword paths----------------------------------------\n",
    "SWORD_path=paste0('/nas/cee-water/cjgleason/calval/SWORD_15/netcdf/',continent,\n",
    "                  '_sword_v15.nc')\n",
    "#------------------------------\n",
    "\n",
    "image_directory=paste0('/nas/cee-water/cjgleason/calval/cnes_watermasks/fromCNES_20230724/',rivername,'/extracteo/') \n",
    "print(image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "182da75d-65ee-4c19-8211-293f5b37826d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Munged drifts/reprocessed_2023_08_22/'"
      ],
      "text/latex": [
       "'Munged drifts/reprocessed\\_2023\\_08\\_22/'"
      ],
      "text/markdown": [
       "'Munged drifts/reprocessed_2023_08_22/'"
      ],
      "text/plain": [
       "[1] \"Munged drifts/reprocessed_2023_08_22/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Munged PT/reprocessed_2023_08_22/'"
      ],
      "text/latex": [
       "'Munged PT/reprocessed\\_2023\\_08\\_22/'"
      ],
      "text/markdown": [
       "'Munged PT/reprocessed_2023_08_22/'"
      ],
      "text/plain": [
       "[1] \"Munged PT/reprocessed_2023_08_22/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Data frames/reprocessed_2023_08_22/'"
      ],
      "text/latex": [
       "'Data frames/reprocessed\\_2023\\_08\\_22/'"
      ],
      "text/markdown": [
       "'Data frames/reprocessed_2023_08_22/'"
      ],
      "text/plain": [
       "[1] \"Data frames/reprocessed_2023_08_22/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Flagged PT/'"
      ],
      "text/latex": [
       "'Flagged PT/'"
      ],
      "text/markdown": [
       "'Flagged PT/'"
      ],
      "text/plain": [
       "[1] \"Flagged PT/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QA_QC_drift_output_directory\n",
    "QA_QC_PT_output_directory\n",
    "reachnode_output_directory\n",
    "flagged_PT_output_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0575e79-2d85-4376-be43-2204d8c58e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a500b3-6c25-40ed-8c27-103dfdd433fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230501T123553_20230501T161922_20230508T181500_1.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230501T123553_20230501T161922_20230508T181500_2.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230501T123553_20230501T161922_20230508T181500_3.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230502T150745_20230502T181514_20230508T184131_1.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230502T150745_20230502T181514_20230508T184131_2.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230515T170401_20230515T212437_20230522T175912_1.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230525T134919_20230525T201724_20230530T224448_1.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230525T134919_20230525T201724_20230530T224448_2.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230525T134919_20230525T201724_20230530T224448_3.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230526T132036_20230526T192852_20230530T232646_1.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230526T132036_20230526T192852_20230530T232646_2.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230531T172921_20230531T211845_20230606T043935_1.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230531T172921_20230531T211845_20230606T043935_2.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230601T172230_20230601T204641_20230606T050705_1.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230601T172230_20230601T204641_20230606T050705_2.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230602T163056_20230602T195104_20230612T190557_1.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230602T163056_20230602T195104_20230612T190557_2.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230612T131510_20230612T210355_20230620T203403_1.csv\"\n",
      "[1] \"Munged drifts/reprocessed_2023_08_22/SWOTCalVal_CR_GNSS_L2_Rec1_20230612T131510_20230612T210355_20230620T203403_2.csv\"\n"
     ]
    }
   ],
   "source": [
    "#create dataframes from drifts---------------------------------------------------------\n",
    "#pull filename before the .csv\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/create_GNSS_dataframe.R')\n",
    "raw_GNSS=sub( \"\\\\..*\",\"\", list.files(GNSS_drift_data_directory,recursive=TRUE))\n",
    "raw_GNSS_river=which(!is.na(do.call(rbind,lapply(raw_GNSS,str_match,rivername))))\n",
    "raw_GNSS=raw_GNSS[raw_GNSS_river]\n",
    "\n",
    "#pull filename before the second _\n",
    "QA_QC_drifts=sub( \"\\\\..*\",\"\",list.files(QA_QC_drift_output_directory))\n",
    "flagged_drifts=sub(\"\\\\..*\",\"\",list.files(flagged_drift_output_directory))\n",
    "#what raw drift data have not been munged\n",
    "unmunged_drifts=setdiff(raw_GNSS,c(flagged_drifts,QA_QC_drifts))\n",
    "\n",
    "#open the key files   \n",
    "if(rivername=='WK'){\n",
    "read_keys=function(keyfile){\n",
    "   this_key= read.csv(keyfile,stringsAsFactors=FALSE)%>%\n",
    "    mutate(keyid=keyfile)%>%\n",
    "    mutate(pt_serial=as.integer(PT_Serial))\n",
    "    }\n",
    "    \n",
    "master_key= do.call(rbind,lapply(PT_key_file,read_keys))}else {master_key=NULL}\n",
    "\n",
    "    # installfile=master_key$Final_Install_Log_File\n",
    "    # takeoutfile= master_key$Final_Uninstall_Log_File\n",
    "    # filenames=c(installfile,takeoutfile)\n",
    "    #  print(filenames)\n",
    "    \n",
    "#print(unmunged_drifts)\n",
    "for (i in 1:length(unmunged_drifts)){\n",
    "create_gnss_dataframe(unmunged_drifts[i],\n",
    "                  gnss_drift_data_directory=GNSS_drift_data_directory,\n",
    "                  output_directory=QA_QC_drift_output_directory,\n",
    "                  keyfile= master_key,\n",
    "                  rivername=  rivername)}\n",
    "\n",
    "\n",
    "#     cl=makeCluster(44)\n",
    "\n",
    "    \n",
    "#   dummy=parLapply(cl=cl,unmunged_drifts,create_gnss_dataframe,\n",
    "#                   gnss_drift_data_directory=GNSS_drift_data_directory,\n",
    "#                   output_directory=QA_QC_drift_output_directory)\n",
    "#   stopCluster(cl)\n",
    "\n",
    "\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "49c8392f-a41e-45b2-b7ff-44ee82a8e49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/nas/cee-water/cjgleason/calval/xml_scripts/CU/Munged/Munged__20230629/SWOTCalVal_WM_PT_L1_PT116_20230510T191500_20230601T220000_20230629T194238.csv\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in left_join(., keyfile, by = \"pt_serial\"):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 1 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 17 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "object has no named columns; assuming order is lon then lat\n",
      "\n",
      "object has no named columns; assuming order is lon then lat\n",
      "\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'pt_time_UTC'. You can override using the\n",
      "`.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'pt_time_UTC'. You can override using the\n",
      "`.groups` argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"SWOTCalVal_WM_PT_L1_PT116_20230510T191500_20230601T220000_20230629T194238_SWOTCalVal_WM_KEY_20230509_20230601.csv\"\n",
      "[1] \"this file passed all checks\"\n"
     ]
    }
   ],
   "source": [
    "#munge PTs if needed------\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/correct_PT_to_GNSS_multikey.R')\n",
    "if (process_PTs==1){\n",
    "dist_thresh=150 # 150m\n",
    "time_thresh= 15*60 #minutes as seconds, centered, so 15 =30 mins total time\n",
    "GNSS_sd_thresh=0.15 # 15cm how much variance do you want in the GNSS data when it is within the distance threshold?\n",
    "offset_sd_thresh=0.10 #m, so 10cm. the the PT apparantly shift by more than a cm?\n",
    "change_thresh_15_min=0.05#m- does it change more than 5cm in 15 minutes? that is a discontinuity in offset\n",
    "\n",
    "#first, move .csv files with an 'L1' in them over to the PT_data_directory\n",
    "munged_files= list.files(PT_data_directory,\n",
    "                         recursive= TRUE)\n",
    "\n",
    "PT_index=which(!is.na(do.call(rbind,lapply(munged_files,str_match,'PT_L1'))))\n",
    "PT_files=munged_files[PT_index]\n",
    "csv_index=which(!is.na(do.call(rbind,lapply(PT_files,str_match,'.csv'))))\n",
    "raw_PT_files=PT_files[csv_index]\n",
    "\n",
    "#open the key files   \n",
    "read_keys=function(keyfile){\n",
    "   this_key= read.csv(keyfile,stringsAsFactors=FALSE)%>%\n",
    "    mutate(keyid=keyfile)%>%\n",
    "    mutate(pt_serial=as.integer(PT_Serial))\n",
    "    }\n",
    "    \n",
    "master_key= do.call(rbind,lapply(PT_key_file,read_keys))\n",
    "    \n",
    "#three key info here-\n",
    "    #1 PTs in the key\n",
    "    #2 unmunged PTs\n",
    "    #3 QA QC PTs\n",
    "    #4 flagged PTs\n",
    "    \n",
    "    #3 + 4 are processed files\n",
    "    \n",
    "getit_processed=function(inputstring){   \n",
    "    output=paste(strsplit(inputstring,'_')[[1]][1:8],collapse='_')\n",
    "    output=sub(\"\\\\..*\",\"\",output)\n",
    "}\n",
    "    \n",
    "getit_key =function(inputstring){   \n",
    "    output=paste(c('SWOTCalVal',rivername,'PT','L1',inputstring),collapse='_')\n",
    "    output=sub(\"\\\\..*\",\"\",output)\n",
    "}\n",
    "    \n",
    "getit_negative=function(longstring, shortstrings){\n",
    "    #search for a pattern between one and many strings with partial matches allows\n",
    "        output=!any(str_detect(longstring,shortstrings)  )\n",
    "}\n",
    "    \n",
    "getit_positive=function(longstring, shortstrings){\n",
    "    #search for a pattern between one and many strings with partial matches allows\n",
    "        output=any(str_detect(longstring,shortstrings))  \n",
    "}\n",
    "       \n",
    "processed_files= do.call(rbind,lapply(c(list.files(QA_QC_PT_output_directory),list.files(flagged_PT_output_directory)),getit_processed))\n",
    "key_files=do.call(rbind,lapply(master_key$Label,getit_key))\n",
    "\n",
    "    if (is.null(processed_files)){unprocessed_files=raw_PT_files}else{\n",
    "unprocessed_files=raw_PT_files[do.call(rbind,lapply(raw_PT_files,getit_negative,processed_files))]}\n",
    "in_key_unprocessed=unprocessed_files[do.call(rbind,lapply(unprocessed_files,getit_positive,key_files))]\n",
    "\n",
    "# print('raw')\n",
    "# print(raw_PT_files)\n",
    "# print('processed')\n",
    "# print(processed_files)\n",
    "# print('unprocessed')\n",
    "# print(unprocessed_files)\n",
    "# print('unprocessed in key')\n",
    "# print(in_key_unprocessed)\n",
    "\n",
    "    \n",
    "for(thisone in in_key_unprocessed){\n",
    "\n",
    "        correct_pt_to_gnss_multikey(thisone,\n",
    "                  master_key=master_key,\n",
    "                  dist_thresh=dist_thresh,\n",
    "                  time_thresh=time_thresh,\n",
    "                  pt_data_directory=PT_data_directory,\n",
    "                  gnss_drift_data_directory=QA_QC_drift_output_directory,\n",
    "                  QA_QC_pt_output_directory=QA_QC_PT_output_directory,\n",
    "                  flagged_pt_output_directory=flagged_PT_output_directory,\n",
    "                  gnss_sd_thresh=GNSS_sd_thresh,\n",
    "                  offset_sd_thresh=offset_sd_thresh,\n",
    "                  change_thresh_15_min=change_thresh_15_min) \n",
    "    \n",
    " \n",
    "}\n",
    "    \n",
    "    \n",
    "    \n",
    "#       cl=makeCluster(20,type='FORK')\n",
    "#   dummy=parLapply(cl, in_key_unprocessed,correct_pt_to_gnss_multikey,\n",
    "#                    master_key=master_key,\n",
    "                  # dist_thresh=dist_thresh,\n",
    "                  # time_thresh=time_thresh,\n",
    "                  # pt_data_directory=PT_data_directory,\n",
    "                  # gnss_drift_data_directory=QA_QC_drift_output_directory,\n",
    "                  # QA_QC_pt_output_directory=QA_QC_PT_output_directory,\n",
    "                  # flagged_pt_output_directory=flagged_PT_output_directory,\n",
    "                  # gnss_sd_thresh=GNSS_sd_thresh,\n",
    "                  # offset_sd_thresh=offset_sd_thresh,\n",
    "                  # change_thresh_15_min=change_thresh_15_min) \n",
    "#   stopCluster(cl)\n",
    "    \n",
    "    }#end if process PT\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c8bc322-9343-4ad8-905b-169a50a02d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>a</th><th scope=col>b</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>4</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & a & b\\\\\n",
       "  & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 4\\\\\n",
       "\t2 & 2 & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 2\n",
       "\n",
       "| <!--/--> | a &lt;int&gt; | b &lt;int&gt; |\n",
       "|---|---|---|\n",
       "| 1 | 1 | 4 |\n",
       "| 2 | 2 | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "  a b\n",
       "1 1 4\n",
       "2 2 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=data.frame(a=1:4,b=4:1)\n",
    "\n",
    "\n",
    "df[!duplicated(t(apply(df[c(\"a\", \"b\")], 1, sort))), ]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f756bb-48ed-4423-b691-8514b2fbda7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linking to GEOS 3.11.1, GDAL 3.6.2, PROJ 9.1.0; sf_use_s2() is TRUE\n",
      "\n",
      "Loading required package: sp\n",
      "\n",
      "Please note that rgdal will be retired by the end of 2023,\n",
      "plan transition to sf/stars/terra functions using GDAL and PROJ\n",
      "at your earliest convenience.\n",
      "\n",
      "rgdal: version: 1.5-32, (SVN revision 1176)\n",
      "Geospatial Data Abstraction Library extensions to R successfully loaded\n",
      "Loaded GDAL runtime: GDAL 3.6.2, released 2023/01/02\n",
      "Path to GDAL shared files: /home/cjgleason_umass_edu/.conda/envs/supposedlybetter/share/gdal\n",
      " GDAL does not use iconv for recoding strings.\n",
      "GDAL binary built with GEOS: TRUE \n",
      "Loaded PROJ runtime: Rel. 9.1.0, September 1st, 2022, [PJ_VERSION: 910]\n",
      "Path to PROJ shared files: /home/cjgleason_umass_edu/.local/share/proj:/home/cjgleason_umass_edu/.conda/envs/supposedlybetter/share/proj\n",
      "PROJ CDN enabled: TRUE\n",
      "Linking to sp version:1.5-1\n",
      "To mute warnings of possible GDAL/OSR exportToProj4() degradation,\n",
      "use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate slopes and heights from drifts within nodes and reaches------\n",
    "\n",
    "SWORD_reach= read.csv(domain_file)\n",
    "this_river_reach_IDs= as.numeric(unique(SWORD_reach$Reach_ID[!is.na(SWORD_reach$Reach_ID)]))\n",
    "this_river_node_IDs= as.numeric(unique(SWORD_reach$Node_ID[!is.na(SWORD_reach$Node_ID)]))\n",
    "\n",
    "\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/calculate_slope_wse_fromdrift.R')\n",
    "\n",
    "\n",
    "dummy=calculate_slope_wse_fromdrift(SWORD_path=SWORD_path,\n",
    "                                    drift_directory=QA_QC_drift_output_directory,\n",
    "                                    PT_directory=PT_directory,\n",
    "                                    output_directory=reachnode_output_directory,\n",
    "                                    this_river_reach_ids=this_river_reach_IDs,\n",
    "                                    this_river_node_ids=this_river_node_IDs,\n",
    "                                    utm_zone=utm_zone, \n",
    "                                    buffer=reach_end_buffer,\n",
    "                                    rivername=rivername,\n",
    "                                    reprocess_switch=reprocess_switch,\n",
    "                                    core_count=core_count)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce47db-c287-4286-b20d-8dfb4bb64670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de238d52-ab26-450a-8aff-8d85e157f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate slopes and heights from PTs within nodes and reaches----\n",
    "if (process_PTs==1){\n",
    "PT_files=paste0(QA_QC_PT_output_directory,list.files(QA_QC_PT_output_directory))\n",
    "SWORD_reach= read.csv(domain_file)\n",
    "this_river_reach_IDs= as.numeric(as.character(unique(SWORD_reach$Reach_ID)))\n",
    "\n",
    " \n",
    "\n",
    "alongstream_error= 0.0001*200 #m error we get from the downstream slope of a reach in a node. This placeholder is a 1e-4 slope over a 200m node\n",
    "crossstream_error= 0.005 #m error we get from PT not representing cross stream superelevation/noise in a node\n",
    "measurement_error= 0.001 #m error we get from PT measurement itself \n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/calculate_slope_wse_fromPT.R')\n",
    "\n",
    "read_keys=function(keyfile){\n",
    "   this_key= read.csv(keyfile,stringsAsFactors=FALSE)%>%\n",
    "    mutate(keyid=keyfile)%>%\n",
    "    mutate(pt_serial=as.integer(PT_Serial))\n",
    "    }\n",
    "    \n",
    "master_key= do.call(rbind,lapply(PT_key_file,read_keys))\n",
    "\n",
    "dummy=calculate_slope_wse_fromPT(keyfile=master_key,\n",
    "                                 pt_files=PT_files,\n",
    "                                 SWORD_path=SWORD_path,\n",
    "                                 SWORD_reach=SWORD_reach,\n",
    "                                 this_river_reach_ids=this_river_reach_IDs,\n",
    "                                 rivername=rivername,\n",
    "                                 output_directory= reachnode_output_directory,\n",
    "                                 alongstream_error=alongstream_error,\n",
    "                                 crossstream_error=crossstream_error,\n",
    "                                 measurement_error=measurement_error)\n",
    "     }\n",
    "#-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a92fb3-131a-40d6-bd24-e67abd5bf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define what drift goes with what SWOT overpass--------------------\n",
    "#SWOT_L2_HR_RiverSP_<FileIdentifier>_<CycleID>_<PassID>_<ContinentID>_<RangeBeginningDateTime>_<RangeEndingDateTime>_<CRID>_<ProductCounter>.<extension> \n",
    "\n",
    "if (process_PTs ==1){\n",
    "passfile=paste0('/nas/cee-water/cjgleason/calval/Processed data/riversp_list_clean_',rivername,'_20230726.txt')\n",
    "\n",
    " \n",
    "passnames=read.delim(passfile,header=F)$V1\n",
    " \n",
    "  \n",
    "time_threshold_sec= 120*60 #two hour\n",
    "wse_threshold_m=0.05 #within 5cm\n",
    "distance_threshold_m =200 #within 200m\n",
    "\n",
    "if (!dir.exists(paste0('Matched_drifts/','processed_',str_replace_all(as.character(Sys.Date()),'\\\\-','_')))){\n",
    "    dir.create(paste0('Matched_drifts/','processed_',str_replace_all(as.character(Sys.Date()),'\\\\-','_')))}\n",
    "\n",
    "\n",
    "matched_output_directory= paste0('Matched_drifts/','processed_',str_replace_all(as.character(Sys.Date()),'\\\\-','_'),'/')\n",
    "munged_drift_directory= QA_QC_drift_output_directory\n",
    "munged_pt_directory=paste0(working_dir,QA_QC_PT_output_directory)\n",
    "\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/select_appropriate_drift.R')\n",
    "\n",
    "read_keys=function(keyfile){\n",
    "   this_key= read.csv(keyfile,stringsAsFactors=FALSE)%>%\n",
    "    mutate(keyid=keyfile)%>%\n",
    "    mutate(pt_serial=as.integer(PT_Serial))\n",
    "    }\n",
    "    \n",
    "master_key= do.call(rbind,lapply(PT_key_file,read_keys))\n",
    "  \n",
    "for (i in 1:length(passnames)){\n",
    "  #  print(passnames[i])\n",
    "   select_appropriate_drift(passnames[i],\n",
    "                               drift_node_directory= paste0(reachnode_output_directory,'/node/'),\n",
    "                               munged_drift_directory=munged_drift_directory,\n",
    "                               matched_output_directory=matched_output_directory,\n",
    "                               munged_pt_directory=munged_pt_directory,\n",
    "                               time_threshold_sec=time_threshold_sec,\n",
    "                               wse_threshold_m= wse_threshold_m,\n",
    "                               distance_threshold_m=distance_threshold_m,\n",
    "                               keyfile=master_key,\n",
    "                               rivername=rivername)\n",
    "    \n",
    "    }\n",
    "\n",
    "  #too memory intensive to parallize. Need to properly paralellize via rslurm to send across the cluster \n",
    "    #rahter than a single node like this\n",
    "#    cl=makeCluster(2,  type = \"FORK\")\n",
    "# dummy=parLapply(cl, passnames,select_appropriate_drift,\n",
    "#                                drift_node_directory= paste0(reachnode_output_directory,'/node/'),\n",
    "#                                munged_drift_directory=munged_drift_directory,\n",
    "#                                matched_output_directory=matched_output_directory,\n",
    "#                                munged_pt_directory=munged_pt_directory,\n",
    "#                                time_threshold_sec=time_threshold_sec,\n",
    "#                                wse_threshold_m= wse_threshold_m,\n",
    "#                                distance_threshold_m=distance_threshold_m,\n",
    "#                                keyfile=master_key,\n",
    "#                                rivername=rivername)\n",
    "\n",
    "#  stopCluster(cl)\n",
    "    \n",
    "    }\n",
    "    \n",
    "#-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57866c3-98a0-4c72-8b0f-db48b26eca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopCluster(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5155e21-63ea-4924-8a93-46b0a4a0d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \">>>> WARNING <<<  attribute _FillValue is an 8-byte value, but R\"\n",
      "[1] \"does not support this data type. I am returning a double precision\"\n",
      "[1] \"floating point, but you must be aware that this could lose precision!\"\n",
      "[1] \"/nas/cee-water/cjgleason/calval/cnes_watermasks/fromCNES_20230724/NS/extracteo//RESULT_20230515_1819_13UCU_S2_EPSG32613.tif\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in write.csv(spatial_node$poly_list, paste0(dir_output, rivername, :\n",
      "“attempt to set 'append' ignored”\n",
      "Warning message in write.csv(spatial_reach$geometry, paste0(dir_output, rivername, :\n",
      "“attempt to set 'append' ignored”\n",
      "Warning message in write.csv(paste0(\"+proj=utm +zone=\", utm_zone, \" +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs +type=crs\"), :\n",
      "“attempt to set 'append' ignored”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 10.49221 mins\n"
     ]
    }
   ],
   "source": [
    "#calcluate areas from images------------------\n",
    "if (process_airborne ==1){\n",
    "\n",
    "a=Sys.time()\n",
    "\n",
    "library(parallel)\n",
    "library(raster)\n",
    "source('/nas/cee-water/cjgleason/calval_toolbox/R code/calculate_area_from_imagery.R')\n",
    "\n",
    "scale_maxwidth = 3\n",
    "#path of input image \n",
    "#image = '/nas/cee-water/cjgleason/calval/Processed data/Imagery/Input/BinaryMap.tif'\n",
    "\n",
    "    #make this use a rivername code\n",
    "imagelist=as.list(list.files(image_directory,full.names=TRUE))\n",
    "    \n",
    " #  print(imagelist)\n",
    "    \n",
    "#make this point to a hub\n",
    "dir_output =paste0('/nas/cee-water/cjgleason/calval/Processed data/',hubname,'/Area/')\n",
    "\n",
    "    image_reaches= unique(read.csv(domain_file)$Reach_ID)\n",
    "    image_nodes=unique(read.csv(domain_file)$Node_ID)\n",
    "    \n",
    "\n",
    "calculate_area_from_imagery(image=imagelist[[1]],\n",
    "                 this_river_reach_ids=image_reaches,\n",
    "                 this_river_node_ids=image_nodes,\n",
    "                 rivercode=rivername,\n",
    "                 utm_zone=utm_zone,\n",
    "                 scale_maxwidth=scale_maxwidth, \n",
    "                 SWORD_path=SWORD_path)\n",
    "\n",
    "# cl=makeCluster(47, type ='FORK')\n",
    "\n",
    "# dummy=parLapply(cl,  imagelist,calculate_area_from_imagery,\n",
    "#                       this_river_reach_ids=image_reaches,\n",
    "#                  this_river_node_ids=image_nodes,\n",
    "#                  rivercode=rivername,\n",
    "#                  utm_zone=utm_zone,\n",
    "#                  scale_maxwidth=scale_maxwidth, \n",
    "#                  SWORD_path=SWORD_path)\n",
    "\n",
    "# stopCluster(cl)\n",
    "    \n",
    " print(Sys.time()-a)#calcluate areas from images----\n",
    "\n",
    " }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "91f5d9e3-1925-457f-b985-5475d8375b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopCluster(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6417fe-771a-48c9-9dc2-93f2cfb50fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:.conda-supposedlybetter]",
   "language": "R",
   "name": "conda-env-.conda-supposedlybetter-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
